# -*- coding: utf-8 -*-
"""Imran Simple Task.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Vkdp-HxGxNAWtDp1lgUF_0yQld2wINDK
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

df = pd.read_csv("/content/Employee Data.csv")
df.head()

df["attendance_pattern"] = df["OvertimePay"] / (df["BaseSalary"] + 1)

df["leave_frequency"] = (
    (df["OvertimePay"] == 0) & (df["LongevityPay"] == 0)
).astype(int)

df["salary_change"] = (
    df["OvertimePay"] + df["LongevityPay"]
) / (df["BaseSalary"] + 1)

df["high_risk"] = (
    (df["attendance_pattern"] > 0.15) |
    (df["leave_frequency"] == 1) |
    (df["salary_change"] > 0.25)
).astype(int)

sns.countplot(x="high_risk", data=df)
plt.title("High-Risk Payroll Records")
plt.show()

X = df[[
    "attendance_pattern",
    "leave_frequency",
    "salary_change"
]]
y = df["high_risk"]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.25, random_state=42
)

lr = LogisticRegression()
lr.fit(X_train, y_train)
lr_acc = accuracy_score(y_test, lr.predict(X_test))

dt = DecisionTreeClassifier(max_depth=2, random_state=42)
dt.fit(X_train, y_train)
dt_acc = accuracy_score(y_test, dt.predict(X_test))

rf = RandomForestClassifier(n_estimators=100,max_depth=2, random_state=58)
rf.fit(X_train, y_train)
rf_acc = accuracy_score(y_test, rf.predict(X_test))

comparison = pd.DataFrame({
    "Model": ["Logistic Regression", "Decision Tree", "Random Forest"],
    "Accuracy": [lr_acc, dt_acc, rf_acc]
})

print(comparison)

feature_importance = pd.DataFrame({
    "Feature": X.columns,
    "Importance": rf.feature_importances_
}).sort_values(by="Importance", ascending=False)

print(feature_importance)

sns.barplot(x="Importance", y="Feature", data=feature_importance)
plt.title("Feature Importance")
plt.show()